{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCAD, pytorch, variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\romer\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\romer\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scad_penalty(beta_hat, lambda_val, a_val):\n",
    "    abs_beta_hat = torch.abs(beta_hat)\n",
    "    is_linear = (abs_beta_hat <= lambda_val) # defining the flat outer bounds\n",
    "    is_quadratic = torch.logical_and(lambda_val < abs_beta_hat, abs_beta_hat <= a_val * lambda_val) # if lambda < absolute value of beta <= a * lambda\n",
    "    is_constant = (a_val * lambda_val) < abs_beta_hat # if absolute value of beta is greater than a * lambda\n",
    "    \n",
    "    linear_part = lambda_val * abs_beta_hat * is_linear\n",
    "    quadratic_part = (2* a_val * lambda_val * abs_beta_hat - beta_hat**2 - lambda_val**2) / (2*(a_val - 1)) * is_quadratic\n",
    "    constant_part = (lambda_val**2*(a_val+1)) / 2 * is_constant\n",
    "\n",
    "    return linear_part + quadratic_part + constant_part\n",
    "\n",
    "def scad_derivative(beta_hat, lambda_val, a_val):\n",
    "    return lambda_val*((beta_hat <= lambda_val) + (a_val*lambda_val-beta_hat)*((a_val*lambda_val-beta_hat) > 0)/((a_val-1)*lambda_val)*(beta_hat>lambda_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan], dtype=torch.float64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scad_derivative(torch.tensor([.5,.5], dtype= dtype, device= device), 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own PyTorch class that implements the method of SCAD regularization and variable selection (smoothly clipped absolute deviations) for linear models. Your development should be based on the following references:\n",
    "https://andrewcharlesjones.github.io/journal/scad.html\n",
    "https://www.jstor.org/stable/27640214?seq=1\n",
    "\n",
    "Test your method on a real data set and determine a variable selection based on features' importance, according to SCAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCADLinear(nn.Module):\n",
    "    def __init__(self, input_size, lambda_val, a_val):\n",
    "        super(SCADLinear, self).__init__() # init nn.Module\n",
    "        self.input_size = input_size\n",
    "        self.lambda_val = lambda_val\n",
    "        self.a_val = a_val\n",
    "\n",
    "        self.linear = nn.Linear(input_size, 1, bias= False, device= device, dtype= dtype)\n",
    "\n",
    "    def forward(self, x): # how necessary is this?\n",
    "        # train the linear model on x\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def scad_derivative(self, beta_hat):\n",
    "        solution = self.lambda_val*((beta_hat <= self.lambda_val) + (self.a_val*self.lambda_val-beta_hat)*((self.a_val*self.lambda_val-beta_hat) > 0)/((self.a_val-1)*self.lambda_val)*(beta_hat>self.lambda_val))\n",
    "        return solution\n",
    "    \n",
    "    def loss_with_scad(self, y_pred, y_true):\n",
    "        mse = nn.MSELoss()(y_pred,y_true)\n",
    "        penalty = torch.squeeze(self.scad_derivative(beta_hat=self.linear.weight))[1]\n",
    "        return mse + penalty\n",
    "    \n",
    "    def fit(self, x, y, num_epochs= 200, learning_rate= .001):\n",
    "        optimize = optim.SGD(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            optimize.zero_grad() # clear the optimizer\n",
    "            y_pred = self(x)\n",
    "            loss_with_scad = self.loss_with_scad(y_pred, y)\n",
    "            loss_with_scad.backward() # computes gradient\n",
    "            optimize.step()\n",
    "\n",
    "            if (epoch+1) % 100 == 0:\n",
    "                print(f'epoch: {epoch+1}/{num_epochs}, loss_with_scad: {loss_with_scad.item()}')\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad(): # forces custom gradient\n",
    "            y_pred = self(x)\n",
    "        return y_pred\n",
    "    \n",
    "    def get_coefficients(self):\n",
    "        return self.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to define a function for generating x with a prescribed number of obsvervations, features and Toeplitz correlation structure.\n",
    "def make_correlated_features(num_samples,p,rho):\n",
    "  vcor = [] \n",
    "  for i in range(p):\n",
    "    vcor.append(rho**i)\n",
    "  r = toeplitz(vcor)\n",
    "  mu = np.repeat(0,p)\n",
    "  x = np.random.multivariate_normal(mu, r, size=num_samples)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.9\n",
    "p = 20\n",
    "n = 150\n",
    "x = make_correlated_features(n, p, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta =np.array([-1,2,3,0,0,0,0,2,-1,4])\n",
    "beta = beta.reshape(-1,1)\n",
    "betastar = np.concatenate([beta,np.repeat(0,p-len(beta)).reshape(-1,1)],axis=0)\n",
    "y = x@betastar + 1.5*np.random.normal(size=(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(x, device=device)\n",
    "y_tensor = torch.tensor(y, device= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SCADLinear(x_tensor.shape[1], 0.5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100/1000, loss_with_scad: 3.5206135602450828\n",
      "epoch: 200/1000, loss_with_scad: 2.9271076025363185\n",
      "epoch: 300/1000, loss_with_scad: 2.5865521456803466\n",
      "epoch: 400/1000, loss_with_scad: 2.3638036336341264\n",
      "epoch: 500/1000, loss_with_scad: 2.2090046517173842\n",
      "epoch: 600/1000, loss_with_scad: 2.0970431059949575\n",
      "epoch: 700/1000, loss_with_scad: 2.013741314192788\n",
      "epoch: 800/1000, loss_with_scad: 1.9504661119917728\n",
      "epoch: 900/1000, loss_with_scad: 1.901651613498697\n",
      "epoch: 1000/1000, loss_with_scad: 1.863542907286052\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_tensor,y_tensor, num_epochs=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.86320628220977"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(model.predict(x_tensor).detach().numpy(), y_tensor.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the simulation design explained in class, generate 200 data sets where the input features have a strong correlation structure (you may consider a 0.9) and apply ElasticNet, SqrtLasso and SCAD to check which method produces the best approximation of an ideal solution, such as a \"betastar\" you design with a sparsity pattern of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the methods you implemented above to determine a variable selection for the Concrete data set with quadratic interaction terms (polynomial features of degree 2). To solve this, you should consider choosing the best weight for the penalty function. What is the ideal model size (number of variables with non-zero weights), and what is the cross-validated mean square error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
